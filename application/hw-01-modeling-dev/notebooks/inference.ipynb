{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0750ea2-a848-4b3e-a520-e4322a1e665c",
   "metadata": {},
   "source": [
    "# Model inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18614bc6-575d-4d32-8d2d-b3778eff79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import gc\n",
    "\n",
    "from os import path\n",
    "import sys\n",
    "sys.path.append(path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dff247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "from src.lightning_module import PlanetsModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "BATCH_SIZE = 1\n",
    "DATA_FOLDER = '../dataset/planet/planet/'\n",
    "ONNX_MODEL_NAME = '../onnx_planet_model.onnx'\n",
    "!ls {DATA_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247496b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем модель\n",
    "checkpoints_folder = '../experiments/experiment2/'\n",
    "# Берем какой-то чекпоинт из папки. Если нужен конкретный - можно явно указать путь\n",
    "checkpoint_name = os.path.join(checkpoints_folder, os.listdir(checkpoints_folder)[0]) \n",
    "module = PlanetsModule.load_from_checkpoint(checkpoint_name)\n",
    "\n",
    "module.eval()\n",
    "module.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8cfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "df = pd.read_csv(os.path.join(DATA_FOLDER, 'df_train_ohe.csv'))\n",
    "names = list(df.columns[1:])\n",
    "names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# препроцессинг данных \n",
    "img_height = 224\n",
    "img_width = 224\n",
    "preprocess = albu.Compose(\n",
    "        [\n",
    "            albu.Resize(height=img_height, width=img_width),\n",
    "            albu.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "image_name = os.path.join(DATA_FOLDER, 'train-jpg', f'{df[\"Id\"][idx]}.jpg')\n",
    "image = cv2.imread(image_name)[..., ::-1]\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c10f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "procecces_image = preprocess(image=image)['image']\n",
    "with torch.no_grad():\n",
    "    scores = torch.sigmoid(module(procecces_image[None].to(DEVICE)))[0].cpu().numpy()\n",
    "    \n",
    "pprint({n:s for s, n in zip(scores, names)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b84a5a-1874-4703-abfe-6559ad8ee9cd",
   "metadata": {},
   "source": [
    "## Torch model with manual data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d10ee7-1dfd-4bfd-b141-88d1d2d05e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "image_name = os.path.join(DATA_FOLDER, 'train-jpg', f'{df[\"Id\"][idx]}.jpg')\n",
    "image = cv2.imread(image_name)[..., ::-1]\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4ddf7-6b78-45d4-bafb-6f4a4347f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_preprocessing(\n",
    "    image,\n",
    "    image_size = (224, 224),\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert numpy-image array for inference Torch model.\n",
    "    \"\"\"\n",
    "    # resize\n",
    "    image = cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # normalize\n",
    "    mean = np.array((0.485, 0.456, 0.406), dtype=np.float32) * 255.0\n",
    "    std = np.array((0.229, 0.224, 0.225), dtype=np.float32) * 255.0\n",
    "    denominator = np.reciprocal(std, dtype=np.float32)\n",
    "    image = image.astype(np.float32)\n",
    "    image -= mean\n",
    "    image *= denominator\n",
    "\n",
    "    # to tensor and transpose\n",
    "    image = torch.from_numpy(image.transpose((2, 0, 1)))[None]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3e8f5-e1f6-4833-8639-f3bbef7ad3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим тензора для прогона\n",
    "torch_input = torch_preprocessing(image).to(DEVICE)\n",
    "torch_input = torch.cat([torch_input] * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a3580-c8eb-42e2-b071-99a2f98ffebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прогон через торчовую модель\n",
    "with torch.no_grad():\n",
    "    torch_output = module(torch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80265d94-ba55-4b8b-882b-1abaea96c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e310a74-a34d-4698-8d99-3202340fcf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_torch = torch.sigmoid(torch_output)[0].cpu().numpy()\n",
    "    \n",
    "pprint({n:s for s, n in zip(scores_torch, names)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6132696-ead6-44e1-943b-d4008bfaafae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c07f0f5-17ff-4dc7-a121-43fa7ab9c306",
   "metadata": {},
   "source": [
    "## Upload onnx model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ee8a7-f43b-44c5-91e0-e19331f3eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доступные провайдеры, на которых можно выполнять вычисления\n",
    "print(ort.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ab213-f249-490f-ba85-8f87ab2d80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем сессию\n",
    "\n",
    "# При инициализации сессии можно указать несколько провайдеров. Это может быть полезно, если хотим запускать код\n",
    "# на разных машинах. Например на машине с GPU у нас сработает CUDAExecutionProvider,\n",
    "# а на машине без GPU CPUExecutionProvider\n",
    "providers = [\n",
    "    # 'CUDAExecutionProvider',\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    ONNX_MODEL_NAME,\n",
    "    providers=providers\n",
    ")\n",
    "\n",
    "print(f'{[input_.name for input_ in ort_session.get_inputs()]}')\n",
    "print(f'{[output_.name for output_ in ort_session.get_outputs()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb03665-3d4a-4782-9caf-40515e14cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_preprocessing(\n",
    "    image,\n",
    "    image_size=(224, 224)\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert numpy-image to array for inference ONNX Runtime model.\n",
    "    \"\"\"\n",
    "\n",
    "    # resize\n",
    "    image = cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # normalize\n",
    "    mean = np.array((0.485, 0.456, 0.406), dtype=np.float32) * 255.0\n",
    "    std = np.array((0.229, 0.224, 0.225), dtype=np.float32) * 255.0\n",
    "    denominator = np.reciprocal(std, dtype=np.float32)\n",
    "    image = image.astype(np.float32)\n",
    "    image -= mean\n",
    "    image *= denominator\n",
    "\n",
    "    # transpose\n",
    "    image = image.transpose((2, 0, 1))[None]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef1a79-68af-4066-82bb-fb4f010e1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим входной тензор\n",
    "onnx_input = onnx_preprocessing(image)\n",
    "onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "print(list(ort_inputs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02433b4b-91d8-491f-a58a-aa8e0c9cb238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполняем инференс ONNX Runtime\n",
    "ort_outputs = ort_session.run(None, ort_inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7467e-6912-4e28-baf1-6b57b38dfdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5444b71-d430-4410-bd1d-71169b11f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_onnx = torch.sigmoid(torch.tensor(ort_outputs))[0].cpu().numpy()\n",
    "    \n",
    "pprint({n:s for s, n in zip(scores_onnx, names)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de20294-dc2a-41fc-9152-df911eea56a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw-01",
   "language": "python",
   "name": "hw-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
